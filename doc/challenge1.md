# Challenge 1: Recovery of Human Body Scans

There are two tracks:

  - Track 1: Recovery of large regions
  - Track 2: Recovery of fine details

with two complementary datasets.

## Dataset splits

In each track, the data is split into train/test/eval sets.
In the first stage of the the competition, the train/test sets are provided.
They contain only the ground-truth shapes, `Y`.
The partial data, `X` must be generated by the participants.
The eval set is provided at a later stage of the competition to generate the
submission for the final evaluation.
In this set, the ground-truth shapes, `Y`, are kept secret until the end of the
competition.
Only some pregenerated partial data, `X`, is shared.

## Track 1: Recovery of Large Regions

Given a partial human body scan, `X`, the goal is to recover the complete scan,
`Y`.

### Training data

Provided:

1. A set of complete scans, `Y`.
2. Additional metadata: The 3D positions of detected body landmarks.

Not provided:

1. The partial scans, `X`. They must be generated by the participants.

Te body landmarks are used to generate the partial data.
They can be freely exploited during training but they are not provided for the
final evaluation.

The data files are arranged in the following directory structure:

```
  train/
    <scan_name>/
      <scan_name>_normalized.npz
      landmarks3d.txt
    .../
  test/
    <scan_name>/
      <scan_name>_normalized.npz
      landmarks3d.txt
    .../
```

For each scan, there is one subdirectory with a unique `<scan_name>`,
e.g. `170410-007-f-1moq-b682-low-res-result`.
The files are:

* `<scan_name>_normalized.npz`:
  The ground-truth raw scan, `Y`, as a textured mesh.
  Stored in a numpy npz archive.
* `landmarks3d.txt`: 3D positions of detected body landmarks.

### Evaluation data

Provided:

1. A set of partial scans, `X`.

Not provided:

1. The ground-truth scans, `Y`.
   (They will be released after the competition.)
2. Additional metadata.

The data files are arranged in the following directory structure:

```
  eval/
    <scan_name>/
      <scan_name>_partial.npz
    .../
```

### Submission format

The predicted complete mesh, `Y'`, should be in `.obj` or `.npz` (see
[formats](formats.md)).

The mesh colour information should be either:

1. a single texture atlas,
2. or RGB colour stored as vertex attributes.

A mixture of vertex colour attribute and texture mapping is not allowed.

The mesh geometry may be different than the input, `X`.

The data files must be organised in this directory structure:

```
  eval/
    <scan_name>/
      <scan_name>_partial.(npz|obj)
    .../
```

where `<scan_name>` is correponds to the input data.


## Track 2: Recovery of Fine Details

The dataset has the following directory structure:

```
  train/
    170926-001-fitness-run-sbt1-d8f6-low-res-result/
      fitted_textured.npz
      fusion_textured.npz
      landmarks3d.txt
```

For each sample, the data is under a subdirectory with a unique name,
e.g. `170926-001-fitness-run-sbt1-d8f6-low-res-result/`.
The data files are:

* `fitted_textured.npz`:
  The reference mesh with details. It is obtained by fitting the SMPL-X body
  model to a body scan and transferring the texture.
* `fusion_textured.npz`:
  The simulated body scan. This is a texture mesh obtained from the fitted body
  model mesh by simulating the scanning process in software. It is less
  detailed and contains artefacts similar to a real 3D scan.
* `landmarks3d.txt`:
  The 3D positions of the 3D landmarks. Common to both meshes.

Both meshes are aligned and in the same frame of reference.

During the final evaluation:

* the reference mesh `Y` is `fitted_textured.npz`,
* the partial views `X` are generated from `fusion_textured.npz`.

See below for details on the file formats.

## 3D body landmarks

The body landmarks are detected automatically on each scan. They are provided
to generate the partial data but can also be used as part of the proposed
method.
They comprise standard body joints and other keypoints on the body (eyes, nose,
ears...). The detection of most landmarks is stable except for the finger
joints which vary in accuracy.

## Data format

### Meshes

The body scans are textured 3D meshes stored in a numpy npz archive.

Load and access arrays from an npz file in Python with

```python
  import numpy as np
  mesh = np.load("name.npz", allow_pickle=True)
  mesh["vertices"]
  mesh["faces"]
  # ...
```

The following fields define a mesh:

* `vertices`, float (N, 3):
    The 3D positions of the vertices. Variable number of vertices across the
    meshes.
* `faces`, int (20000, 3):
    The vertex indices defining the faces in 3D space (i.e. triplets of indices
    into the `vertices` array). Fixed number of faces (20000) for all meshes.
* `texcoords`, float (Nt, 2):
    The 2D positions of the vertices in the texture atlas (Nt > N).
* `texcoords_indices`, int (20000, 3):
    The vertex indices defining the faces in the UV space (2D texture image)
    (i.e. triplets of indices into the `texcoords` array). Fixed number of
    faces (20000) for all meshes
* `texture`, uint8 (2048, 2048, 3):
    The RGB texture image.

(Other existing fields are either empty and/or should not be relied upon.)

### Landmarks

The landmarks as stored in space-separated text file with columns

```
  name x y z
```

where `name` is the name of the landmark, and `(x, y, z)` is its 3D position in
the frame of reference the scan or meshes.

For example,

```
  elbow_left 1.234 0.123 0.389
```
